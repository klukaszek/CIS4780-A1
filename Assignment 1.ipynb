{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS 4780 - Assignment 1\n",
    "\n",
    "Name: Kyle Lukaszek\n",
    "\n",
    "ID: 1113798\n",
    "\n",
    "Due: 10/5/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - KNN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define KNN Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier:\n",
    "    def __init__(self):\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = torch.tensor(X_train)\n",
    "        self.y_train = torch.tensor(y_train)\n",
    "\n",
    "    def predict(self, X_test, k):\n",
    "        y_pred = []\n",
    "\n",
    "        for x_test in X_test:\n",
    "            # Calculate euclidian distances from the test point to all training points\n",
    "            distances = torch.norm(self.X_train - torch.tensor(x_test), dim=1)\n",
    "\n",
    "            # Sort euclidean distances and get the indices of the k-nearest neighbors\n",
    "            indices = torch.argsort(distances)[:k]\n",
    "\n",
    "            # Get the labels of the k-nearest neighbors\n",
    "            neighbors_labels = self.y_train[indices]\n",
    "\n",
    "            # Predict/classify the label by taking the majority vote (i.e. the sign of the sum)\n",
    "            prediction = torch.sign(torch.sum(neighbors_labels))\n",
    "\n",
    "            # Append the prediction/classification to the list of predictions\n",
    "            y_pred.append(prediction.item())\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define KNN K-fold Cross Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_k_fold_cross_validation(X, y, k_values):\n",
    "    # Initialize lists to store accuracy scores for training and testing\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Define the number of folds for cross-validation\n",
    "    num_folds = 10\n",
    "\n",
    "    # Initialize K-fold cross-validation using sci-kit learn's KFold class\n",
    "    # It is better to shuffle the data before splitting it into folds\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    # Loop through different K values\n",
    "    for k in k_values:\n",
    "        fold_accuracies_train = []\n",
    "        fold_accuracies_test = []\n",
    "\n",
    "        # Loop through different folds of the data\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Initialize and fit the KNN classifier on the training data\n",
    "            knn = KNNClassifier()\n",
    "            knn.fit(X_train, y_train)\n",
    "\n",
    "            # Calculate accuracy for this fold using the current K value\n",
    "            train_predictions = knn.predict(X_train, k)\n",
    "            test_predictions = knn.predict(X_test, k)\n",
    "\n",
    "            train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "            test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "            fold_accuracies_train.append(train_accuracy)\n",
    "            fold_accuracies_test.append(test_accuracy)\n",
    "\n",
    "        # Calculate the average accuracy over all folds for this K value\n",
    "        avg_train_accuracy = np.mean(fold_accuracies_train)\n",
    "        avg_test_accuracy = np.mean(fold_accuracies_test)\n",
    "\n",
    "        train_accuracies.append(avg_train_accuracy)\n",
    "        test_accuracies.append(avg_test_accuracy)\n",
    "\n",
    "    return train_accuracies, test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data And Run KNN Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'KNNClassifierInput.csv'\n",
    "output_file = 'KNNClassifierOutput.csv'\n",
    "\n",
    "# Load input data from the input file using Pandas\n",
    "input_df = pd.read_csv(input_file, header=0)\n",
    "\n",
    "# Load output data from the output file using Pandas\n",
    "output_df = pd.read_csv(output_file)\n",
    "\n",
    "# Remove empty columns from output data\n",
    "output_df = output_df.dropna(axis=1)\n",
    "\n",
    "# Convert input data to np array\n",
    "X = input_df[['Input 1', 'Input 2']].values\n",
    "\n",
    "# Convert output data to np array\n",
    "y = output_df.values.squeeze()\n",
    "\n",
    "# Define the range of K values to test\n",
    "k_values = list(range(1, 31))  # Test K from 1 to 30\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "train_accuracies, test_accuracies = knn_k_fold_cross_validation(X, y, k_values)\n",
    "\n",
    "# Select the best K based on testing accuracy\n",
    "best_k = k_values[np.argmax(test_accuracies)]\n",
    "print(f'Best K Value: {best_k}')\n",
    "print(f'Test Accuracy with Best K Value: {max(test_accuracies) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy for different K values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(k_values, test_accuracies, label='Testing Accuracy')\n",
    "plt.title('KNN Accuracy vs. K Value')\n",
    "plt.xlabel('K (Number of Neighbors)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Value Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write analysis here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Linear Regression (Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Ridge Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        # Initialize the parent class (nn.Module)\n",
    "        super(RidgeRegression, self).__init__()\n",
    "        # Define the linear layer\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define PyTorch Z-Score Normalization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple implementation based on sklearn.preprocessing.StandardScaler\n",
    "class ZScoreNormalizer:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        # Calculate the mean and standard deviation along dim 0 (columns)\n",
    "        self.mean = torch.mean(data, dim=0)\n",
    "        self.std = torch.std(data, dim=0)\n",
    "\n",
    "    def transform(self, data):\n",
    "        if self.mean is None or self.std is None:\n",
    "            raise ValueError(\"Not fitted yet. Call fit() before transform()\")\n",
    "        \n",
    "        # z = (X - mean) / std\n",
    "        normalized_data = (data - self.mean) / self.std\n",
    "        return normalized_data\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Ridge Regression K-fold Cross Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_k_fold_cross_validation(X, y, model, criterion, optimizer, num_epochs=100, lambda_val=0.0, k_folds=5):\n",
    "    # Initialize lists to store accuracy scores for training and testing\n",
    "    train_losses = []  # To store training losses for each fold\n",
    "    test_losses = []   # To store testing losses for each fold\n",
    "    r2_scores = []     # To store R2 scores for each fold\n",
    "    mse_scores = []    # To store Mean Squared Error scores for each fold\n",
    "\n",
    "    # Define the number of folds for cross-validation (in this case it is 5 per the assignment)\n",
    "    num_folds = 5\n",
    "\n",
    "    # Initialize K-fold cross-validation using sci-kit learn's KFold class\n",
    "    # It is better to shuffle the data before splitting it into folds\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    # Loop through different folds of the data\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "            \n",
    "        # Zero out the gradients in the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Training Loop\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Forward pass: compute predictions\n",
    "            outputs = model(X_train)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, y_train)\n",
    "            \n",
    "            # Add L2 regularization term to the loss\n",
    "            l2_reg = lambda_val * torch.sum(model.linear.weight ** 2)\n",
    "            loss += l2_reg\n",
    "            \n",
    "            # Backward pass: compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            \"\"\"\n",
    "            Note: \n",
    "            Gradient clipping prevents a NaN error due to exploding gradients in my case, I am not sure if there is an error in my implementation but I thought I should mention it.\n",
    "            I could have used a smaller learning rate for the optimizer but I found that gradient clipping results in more consistent results.\n",
    "            \"\"\"\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # Update the model's parameters\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        # Set the model to evaluation mode (no gradient computation)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Compute predictions on the training and testing data\n",
    "            train_outputs = model(X_train)\n",
    "            test_outputs = model(X_test)\n",
    "\n",
    "            # Calculate training and testing losses\n",
    "            train_loss = criterion(train_outputs, y_train)\n",
    "            test_loss = criterion(test_outputs, y_test)\n",
    "            \n",
    "            # Calculate R2 score and Mean Squared Error for testing data\n",
    "            r2 = r2_score(y_test, test_outputs)\n",
    "            mse = mean_squared_error(y_test, test_outputs)\n",
    "\n",
    "        # Store the results for this fold\n",
    "        train_losses.append(train_loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "        r2_scores.append(r2)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    # Calculate average results over all folds\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    avg_r2_score = np.mean(r2_scores)\n",
    "    avg_mse_score = np.mean(mse_scores)\n",
    "\n",
    "    return {\n",
    "        'avg_train_loss': avg_train_loss,\n",
    "        'avg_test_loss': avg_test_loss,\n",
    "        'avg_r2_score': avg_r2_score,\n",
    "        'avg_mse_score': avg_mse_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data And Run Linear Regression Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'LinearRegression.csv'\n",
    "target_file = 'LinearRegressionTarget.csv'\n",
    "\n",
    "# Load the input data\n",
    "input_data_df = pd.read_csv(input_file)\n",
    "\n",
    "# Load the target data\n",
    "target_data_df = pd.read_csv(target_file)\n",
    "\n",
    "# Get input data to a PyTorch tensor\n",
    "input_tensor = torch.tensor(input_data_df.values, dtype=torch.float32)\n",
    "\n",
    "# Get target values as a PyTorch tensor\n",
    "target_tensor = torch.tensor(target_data_df.values, dtype=torch.float32)\n",
    "\n",
    "# Normalize input data using custom ZScoreNormalizer class\n",
    "input_normalizer = ZScoreNormalizer()\n",
    "input_tensor = input_normalizer.fit_transform(input_tensor)\n",
    "\n",
    "# Normalize target data using custom ZScoreNormalizer class\n",
    "target_normalizer = ZScoreNormalizer()\n",
    "target_tensor = target_normalizer.fit_transform(target_tensor)\n",
    "\n",
    "# Initialize hyperparameters\n",
    "input_dim = input_tensor.shape[1]  # Adjust this according to your dataset\n",
    "num_epochs = 100\n",
    "\n",
    "# Lambda values from [0, 250]\n",
    "lambda_values = list(range(0, 251))\n",
    "results = []\n",
    "\n",
    "# Perform Ridge Regression with cross-validation for different lambda values\n",
    "for lambda_val in lambda_values:\n",
    "    model = RidgeRegression(input_dim)\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    \"\"\" \n",
    "    Note: \n",
    "    I used a learning rate of 0.01 because I used gradient clipping to prevent exploding gradients (see the lr_k_fold_cross_validation function above).\n",
    "    I messed around with using a smaller learning rate (e.g. 0.001) and no gradient clipping but I found that this resulted in a lower R2 score and larger avg losses.\n",
    "    Therefore, I decided to use a larger learning rate with gradient clipping to get the best results with my implementation.\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    cv_results = lr_k_fold_cross_validation(input_tensor, target_tensor, model, criterion, optimizer, num_epochs, lambda_val)\n",
    "    results.append((lambda_val, cv_results))\n",
    "\n",
    "# Find the lambda with the best average R2 score\n",
    "best_lambda, best_results = max(results, key=lambda x: x[1]['avg_r2_score'])\n",
    "\n",
    "# Print lambda results for lambda=0\n",
    "print(\"Results for lambda=0:\")\n",
    "print(results[0][1]) \n",
    "\n",
    "# Print lambda results for best lambda\n",
    "print(f\"\\nBest lambda: {best_lambda}\")\n",
    "print(\"Results for best lambda:\")\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Ridge Regression R2 Results and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot R2 scores for different lambda values\n",
    "r2_scores = [result[1]['avg_r2_score'] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambda_values, r2_scores)\n",
    "plt.title('R2 Score vs. Lambda')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Average R2 Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot MSE scores for different lambda values\n",
    "mse_scores = [result[1]['avg_mse_score'] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambda_values, mse_scores)\n",
    "plt.title('MSE Score vs. Lambda')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Average MSE Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Lambda Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write analysis here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: K-Nearst Neighbor Classifier VS Logistic Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
